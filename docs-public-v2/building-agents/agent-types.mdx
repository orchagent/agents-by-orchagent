---
title: "Agent Types"
description: "Understanding agents and skills on orchagent"
---

orchagent hosts two types of content: **agents** that execute tasks, and **skills** that provide reusable knowledge.

## Agents vs Skills: The Simple Rule

| | Agents | Skills |
|---|--------|--------|
| **What they do** | **DO** things (execute tasks) | **TEACH** things (provide knowledge) |
| **Nature** | Active executors | Passive knowledge |
| **Commands** | `orch run`, `orch install` | `orch skill install` |
| **Output** | Structured results | Context files for AI tools |

<Info>
**Quick distinction:** Agents *do* things. Skills *inform* agents how to do things better.
</Info>

## At a Glance

orchagent supports three agent types, each designed for different levels of complexity:

| | Prompt | Agent | Tool | Skill |
|-|--------|-------|------|-------|
| **Purpose** | Single LLM call | LLM with tools in a sandbox | Full custom code | Provide knowledge |
| **You provide** | Prompt + schemas | Prompt + custom tools | Python/JS code | SKILL.md file |
| **Code required** | None | None | Yes (all of it) | None |
| **Sandbox** | No | Yes (E2B) | Yes (E2B) | No |
| **LLM handling** | Platform handles | Platform handles | You handle | N/A |
| **Best for** | Extraction, summarization | Multi-step tool-use workflows | Full control, non-LLM tasks | Standards, guidelines |

## Which Type Should I Use?

```
I want to build something on orchagent
  │
  ├─ Does it need an LLM to think and decide?
  │   │
  │   ├─ Yes
  │   │   │
  │   │   ├─ Simple (one call, no tools) → Prompt
  │   │   │   "Just an LLM call with your prompt and schema"
  │   │   │
  │   │   └─ Complex (tools, iteration, sandbox) → Agent
  │   │       "Give it a prompt + tools, platform runs the loop"
  │   │
  │   └─ No → Tool
  │       "Your code, our sandbox. Deterministic, fast, cheap."
  │
  └─ I want to share knowledge → Skill
      "Markdown instructions that enhance any agent"
```

<Tip>
**Start with the simplest type that works.** Most use cases should be prompt agents. If you need tools, try agent. Only reach for tool when you need full programmatic control or don't need an LLM.
</Tip>

---

## Prompt Agents

The simplest agent type. You provide a prompt template with variable placeholders, and orchagent handles the LLM call.

**When to use:**
- Single LLM call is sufficient
- No external API calls needed
- No complex logic or branching

**What you provide:**
```
my-prompt-agent/
├── orchagent.json      # Agent manifest (type: "prompt")
├── prompt.md           # Your prompt template
├── schema.json         # Input/output schemas (optional)
└── README.md           # Documentation (optional)
```

### Example

**`orchagent.json`:**
```json
{
  "name": "sentiment-analyzer",
  "type": "prompt",
  "description": "Analyze sentiment of text",
  "supported_providers": ["openai", "anthropic"]
}
```

**`prompt.md`:**
```markdown
Analyze the sentiment of the following text and return a JSON object
with 'sentiment' (positive, negative, or neutral) and 'confidence' (0-1).

Text: {{text}}
```

**`schema.json`:**
```json
{
  "input": {
    "type": "object",
    "properties": {
      "text": { "type": "string", "description": "Text to analyze" }
    },
    "required": ["text"]
  },
  "output": {
    "type": "object",
    "properties": {
      "sentiment": { "type": "string", "enum": ["positive", "negative", "neutral"] },
      "confidence": { "type": "number", "minimum": 0, "maximum": 1 }
    }
  }
}
```

### Prompt Variables

Use `{{variable}}` syntax in your `prompt.md`:

```
Summarize the following {{document_type}} in {{language}}:

{{content}}

Focus on: {{focus_areas}}
```

Variables are replaced with input values at runtime. All template variables must be provided with non-empty values — the API returns a `400 MISSING_INPUT_FIELDS` error listing any that are missing.

---

## Agents

Agents give the LLM a **tool-use loop inside a sandbox**. Think of it as "Claude Code in a container, configured by you." The platform provides built-in tools (bash, file read/write, list files) and you can define custom command-wrapper tools. The LLM iterates autonomously until it solves the task and submits a result.

**When to use:**
- The task requires running commands, reading/writing files, or iterating
- You want the LLM to figure out the steps, not hard-code them
- You'd otherwise write a tool just to orchestrate LLM + subprocess calls

**What you provide:**
```
my-agent/
├── orchagent.json      # Agent manifest (type: "agent", custom_tools)
├── prompt.md           # Agent instructions (system prompt)
├── schema.json         # Input/output schemas (optional)
├── Dockerfile          # Custom environment (optional)
└── requirements.txt    # Extra sandbox deps (optional)
```

**What the platform provides:**
1. E2B sandbox with your custom environment (if Dockerfile provided)
2. Built-in tools: `bash`, `read_file`, `write_file`, `list_files`, `submit_result`
3. Your custom tools converted to named tool definitions
4. An agentic loop that runs until the LLM calls `submit_result` or hits `max_turns`

### Example: Cairo Test Engineer

This agent fixes Cairo code until tests pass — with **zero lines of orchestration code**.

**`orchagent.json`:**
```json
{
  "name": "cairo-test-engineer",
  "type": "agent",
  "description": "Fixes Cairo code until tests pass",
  "supported_providers": ["anthropic"],
  "max_turns": 30,
  "timeout_seconds": 300,
  "custom_tools": [
    {
      "name": "run_tests",
      "description": "Run the Cairo test suite with snforge",
      "command": "snforge test"
    },
    {
      "name": "build_project",
      "description": "Build the scarb project",
      "command": "scarb build"
    },
    {
      "name": "format_code",
      "description": "Format Cairo source files",
      "command": "scarb fmt"
    }
  ]
}
```

**`prompt.md`:**
```markdown
You are a Cairo test engineer. You have scarb and snforge installed.

Given source files and test files in the input:
1. Create a scarb project directory structure
2. Write the source and test files
3. Run tests using the run_tests tool
4. If tests pass, submit the result with the passing output
5. If tests fail, analyze the errors, fix the code, and try again
6. Keep iterating until tests pass or you've tried 5 times

Submit your final result with test output and any fixes applied.
```

### Before vs After

Without the agent type, this same workflow required **200+ lines of Python** handling the Claude API calls, retry loops, file scaffolding, error analysis, and file merging. With agents, it's just a prompt and a few tool definitions.

### Custom Tools

Custom tools are command wrappers that give the LLM clean, named operations instead of having to guess shell commands.

**Simple tools** (no parameters):
```json
{
  "name": "run_tests",
  "description": "Run the test suite",
  "command": "pytest"
}
```

**Tools with parameters** (use `{{param}}` placeholders):
```json
{
  "name": "deploy",
  "description": "Deploy to the specified network",
  "command": "sncast deploy --network {{network}}",
  "input_schema": {
    "type": "object",
    "properties": {
      "network": { "type": "string", "description": "Target network (testnet/mainnet)" }
    },
    "required": ["network"]
  }
}
```

The LLM sees named tools like `run_tests` and `deploy` instead of guessing raw bash commands. Bash is always available as a fallback for ad-hoc commands.

### Built-in Tools

Every agent automatically gets these tools:

| Tool | Description |
|------|-------------|
| `bash` | Run shell commands (120s per-command timeout) |
| `read_file` | Read file contents |
| `write_file` | Write/create files (auto-creates parent directories) |
| `list_files` | List directory contents (optional recursive) |
| `submit_result` | Submit final structured output and end the loop |

### Safety Limits

| Limit | Default | Configurable |
|-------|---------|-------------|
| `max_turns` | 25 | Yes, in orchagent.json (platform max: 50) |
| Per-command timeout | 120 seconds | No |
| Overall timeout | Agent's `timeout_seconds` | Yes |

### Provider Support

Agents currently support **Anthropic only** (Claude). This is because Anthropic has the best tool-use support. More providers will be added in the future.

---

## Tools

Tools run your Python or JavaScript in **E2B sandboxes** — secure, isolated environments. Each call spins up a fresh sandbox, runs your script, and returns the result. You have full control over everything.

**When to use:**
- You need full programmatic control over the execution flow
- Your use case doesn't need an LLM at all (pure data processing, file conversion, etc.)
- You need multi-model orchestration (calling different LLMs for different steps)
- You have an existing codebase you want to wrap as a tool
- Agents don't give you enough control

### Example

```python
# main.py
import json
import sys

def main():
    # Read input from stdin
    input_data = json.load(sys.stdin)
    repo_url = input_data.get("repo_url")

    # Your logic here: clone repo, scan files, call LLM, etc.
    result = {
        "issues": ["Found hardcoded API key in config.py"],
        "risk_score": 0.7
    }

    # Write output to stdout
    print(json.dumps(result))

if __name__ == "__main__":
    main()
```

### Input/Output Contract

Tools communicate via stdin/stdout as JSON.

**Standard input:**
```json
{"repo_url": "https://github.com/user/repo"}
```

**File uploads:** When files are uploaded, you receive a manifest:
```json
{
  "files": [
    {
      "path": "/tmp/uploads/invoice.pdf",
      "original_name": "invoice.pdf",
      "content_type": "application/pdf",
      "size_bytes": 1234567
    }
  ]
}
```

**Standard output:**
```json
{"issues": ["..."], "risk_score": 0.7}
```

### Directory Structure

```
my-tool/
├── orchagent.json      # Agent configuration
├── main.py             # Entry point
├── requirements.txt    # Dependencies
└── README.md           # Documentation (optional)
```

The CLI auto-detects entrypoints: `main.py`, `app.py`, `index.py`, `main.js`, `index.js`. Override with:

```json
{"entrypoint": "run.py"}
```

### Skills in Tools

Tools can access skills at runtime. When skills are passed via the `--skills` flag or `X-Orchagent-Skills` header, they are mounted as files in your sandbox:

```python
import os
from pathlib import Path

skills_dir = os.environ.get("ORCHAGENT_SKILLS_DIR")
if skills_dir:
    skills_path = Path(skills_dir)

    # Read all skill files
    for skill_file in skills_path.glob("*.md"):
        content = skill_file.read_text()
        # Use skill content in your prompts or logic

    # Or read the manifest for metadata
    import json
    manifest = json.loads((skills_path / "manifest.json").read_text())
    for skill in manifest:
        print(f"Skill: {skill['org']}/{skill['name']}@{skill['version']}")
```

Skills are written to `/home/user/orchagent/skills/` with filenames like `org_name_version.md`. A `manifest.json` file provides metadata for programmatic access.

---

## Skills

Skills are passive knowledge — markdown files containing instructions, rules, or expertise that enhance agents.

**Use cases:**
- Coding standards (React patterns, security rules)
- Domain knowledge (legal requirements, company policies)
- Writing guidelines (tone, formatting, brand voice)

### SKILL.md Format

Skills use the [Agent Skills](https://agentskills.io) standard:

```markdown
---
name: react-best-practices
description: React optimization patterns for performance-critical apps
license: MIT
metadata:
  author: yourname
  version: "1.0"
---

## Rules

- Use functional components over class components
- Memoize expensive computations with useMemo
- Avoid inline function definitions in JSX
```

### Frontmatter Fields

| Field | Required | Description |
|-------|----------|-------------|
| `name` | Yes | Lowercase, hyphens only, max 64 chars |
| `description` | Yes | When to use this skill (max 1024 chars) |
| `license` | No | e.g., MIT |
| `metadata` | No | Author, version, etc. |

### Using Skills

**Install locally** for any AI coding tool:

```bash
# Install to current project
orch skill install yourorg/react-best-practices

# Install globally (available in all projects)
orch skill install yourorg/react-best-practices --global

# Install to specific formats only
orch skill install yourorg/react-best-practices --format claude-code,cursor
```

Writes to `.claude/skills/`, `.cursor/skills/`, `.codex/skills/`, `.agent/skills/`.

**Compose with agents** at run time:

```bash
orch run yourorg/code-reviewer --skills yourorg/react-best-practices
```

### Using Agents as Sub-Agents

Export agents as sub-agent configuration files for AI tools:

```bash
# Install agent as Claude Code sub-agent
orch install yourorg/code-reviewer

# Install to Cursor
orch install yourorg/code-reviewer --format cursor

# Install to project only
orch install yourorg/code-reviewer --scope project

# Update installed agents
orch update
```

See [CLI Commands](/using-agents/cli-commands#install) for full details.

---

## LLM Provider Configuration

Specify supported providers in your manifest:

```json
{"supported_providers": ["openai", "anthropic", "gemini"]}
```

Use `"any"` if your agent works with any provider:

```json
{"supported_providers": ["any"]}
```

<Note>
Agents (type `"agent"`) currently only support `"anthropic"`. This will be expanded in the future.
</Note>

---

## Choosing the Right Type

| Create a **Skill** when... | Create a **Prompt** when... | Create an **Agent** when... | Create a **Tool** when... |
|---------------------------|----------------------------------|------------------------------------|---------------------------------|
| You have knowledge to share | A single LLM call is enough | The LLM needs to use tools and iterate | You need full programmatic control |
| Content is reusable across contexts | No sandbox or file access needed | You'd otherwise write boilerplate orchestration | Your use case doesn't need an LLM |
| No structured I/O needed | Input/output is straightforward | The task involves running commands or editing files | You need multi-model orchestration |
| Instructions could help any agent | No retry logic needed | You want the LLM to figure out the steps | You have existing code to wrap |

## Next Steps

<CardGroup cols={2}>
  <Card title="Manifest Format" icon="file-code" href="/building-agents/manifest-format">
    Full orchagent.json schema
  </Card>
  <Card title="Publishing" icon="upload" href="/building-agents/publishing">
    Publish your agent or skill
  </Card>
  <Card title="Orchestration" icon="diagram-project" href="/building-agents/orchestration">
    Compose agents and skills
  </Card>
</CardGroup>
